library(jsonlite)
library(mongolite)
library("lubridate")
library(maps)
library(httr)
# l'API fournit les données d'aujourdui et des 3 jours à venir
startdate <- Sys.Date()
enddate <- Sys.Date()+3
start_date<- as.character(startdate)
end_date<- as.character(enddate)
#Les villes traitées
townList <-  c("Paris", "Nice","Strasbourg", "Bordeaux", "Le Havre", "Lille",
"Angers","Brest","Marseille", "Toulouse", "Nantes", "Montpellier",
"Rennes", "Dijon", "Amiens","Rouen")
# Pour récupérer la longitude et la latitude d'une ville à partir de son nom
z<-as.data.frame(world.cities)
#Connexion à la base de de données AKZN et à la collection AirQuality
con <- mongo (collection = "AirQuality" , url="mongodb://127.0.0.1:27017/AKZN")
con$remove('{}')
#Stocker les données relatives à chaque ville
for ( ville  in townList) {
city <-z[ z$name== ville & z$country.etc=='France',]
lat <- city$lat
long <- city$long
latt <- as.character(lat)
longg <- as.character(long)
#Construire l'url et faire appel à 'API OPEN METEO
url <- paste0("https://air-quality-api.open-meteo.com/v1/air-quality?latitude=",latt,"&longitude=", longg, "&hourly=pm10,pm2_5,carbon_monoxide,nitrogen_dioxide,sulphur_dioxide,ozone,european_aqi&start_date=",start_date, "&end_date=", end_date)
res = GET(url)
#Ajouter le nom de la ville aux données récupérées
data <- fromJSON(rawToChar(res$content))
data <- append(data, c(ville), after =0)
names(data)[[1]] <- "ville"
#Stocker les données dans la base de données AKZN et dans la collection AirQuality
con$insert(data)
}
## insertion les données de l'API forcast  ""
library(httr)
#library(jsonlite)
library(mongolite)
library(rjson)
villes=c("Paris","Lyon","Nice",
"Strasbourg",
"Bordeaux ",
"Le Havre",
"Lille",
"Angers",
"Brest",
"Nîmes",
"Marseille",
"Toulouse",
"Nantes",
"Montpellier",
"Rennes",
"Saint-Étienne",
"Dijon",
"Amiens",
"Rouen"
)
codeville=c(2988507,
2996943,
2990439,
2973783,
3031582,
3003796,
2998324,
3037656,
6448047,
2990362,
2995468,
2972315,
2990968,
2992166,
2983989,
2980288,
3021372,
3037854,
2982652
)
for (item in  codeville) {
# recupération de l'api
res = GET(paste0("https://api.openweathermap.org/data/2.5/weather?id=",item,"&APPID=af2f6b280ae76a3d215f081e0c014235"))
#print(res$content)
data = fromJSON(rawToChar(res$content))
class(data)
#df=data.frame(data)
visibility=data$visibility
main=data.frame(data$main)
coord=data.frame(data$coord)
#View(coord)
weather=data.frame(data$weather)
#print(weather[1,])
wind=data.frame(data$wind)
clouds=data.frame(data$clouds)
sys=data.frame(data$sys)
id=data$id
name=data$name
df=data.frame(
id=id,
name=name,
visibility=visibility
)
df$main=main
df$wind=wind
df$sys=sys
df$weather=weather[1,]
#View(weather)
df$clouds=clouds
df$coord=coord
nrow(df)
x=toJSON(df)
# creation d'une collection forcast
weatherCollection = mongo(collection = "CWeather", db = "AKZN")
# get first document
# verifier l'existance du document par son identifiant
nb=weatherCollection$count(query = paste0('
{
"id": ',item,'
}'))
# si le document n'existe pas , on insere un nouveau
if(nb==0){
weatherCollection$insert(df)
}
#sinon on remplace le document par un nouveau
if(nb==1){
weatherCollection$replace(query = paste0('
{
"id": ',item,'
}'), update=toJSON(df))
}
}
#print(mongo(db = "test"))
#print(weatherCollection$find(limit=1))
## insertion les données de l'API forcast  ""
library(httr)
library(jsonlite)
library(mongolite)
villes=c("Paris","Lyon","Nice",
"Strasbourg",
"Bordeaux ",
"Le Havre",
"Lille",
"Angers",
"Brest",
"Nîmes",
"Marseille",
"Toulouse",
"Nantes",
"Montpellier",
"Rennes",
"Saint-Étienne",
"Dijon",
"Amiens",
"Rouen"
)
codeville=c(2988507,
2996943,
2990439,
2973783,
3031582,
3003796,
2998324,
3037656,
6448047,
2990362,
2995468,
2972315,
2990968,
2992166,
2983989,
2980288,
3021372,
3037854,
2982652
)
for (item in  codeville) {
#print(item)
# recupération de l'api
res = GET(paste0("https://api.openweathermap.org/data/2.5/forecast?id=",item,"&APPID=af2f6b280ae76a3d215f081e0c014235"))
#print(res$content)
data = fromJSON(rawToChar(res$content))
#cat(toJSON(data))
#class(data)
#print(data)
city=data$city
#View(data)
forcast=data$list
#class(forcast)
#View(forcast)
# visualiser la structure
#dput(head(forcast))
# creation d'une collection forcast
forcastCollection = mongo(collection = "forcast", db = "AKZN")
# get first document
#df2 = forcastCollection$find(limit=1)
# visualiser la structure du dataframe
#dput(head(df2))
# insert API data in collection
ID=c("1")
df <- data.frame(ID)
# create le document du mongodb sou forme du datafrmae (chaque ligne dans le DF represente un document)
ville=data.frame(name=c(city$name),
id=city$id,
coord=city$coord,
sunrise=c(city$sunrise),
sunset=c(city$sunset)
)
df$city <- ville
#View(df)
df$list <-list(data$list)
#View(list(data$list))
#dput(head(list(data.frame(data$list))))
#View(list(data.frame(data$list)))
# insertion du document dans la collection
nb= forcastCollection$count(query = paste0('
{
"city.id": ',item,'
}'))
if(nb==0){
forcastCollection$insert(toJSON(data))
}
if(nb==1){
forcastCollection$replace(query = paste0('
{
"city.id": ',item,'
}'), update=toJSON(data))
}
}
#print(weatherCollection$find(limit=1))
# This script updates the horoscope collection in our mongo data base
# It should be called once a day
# It makes sure that the collection has the right structure (number of docs and value fields for the sign names)
# Then updates it by calling the aztro API
# API doc : https://rapidapi.com/sameer.kumar/api/aztro/
library(mongolite)
library(httr)
sign_name <- c('aries', 'taurus', 'gemini', 'cancer',
'leo', 'virgo', 'libra', 'scorpio',
'sagittarius', 'capricorn', 'aquarius', 'pisces')
#connect to the collection and db
horoscope <- mongo(collection = "horoscope", db = "AKZN")
#get the number of documents in the collection
nb.docs <- horoscope$count()
#if nb.docs != 0 and != 12, then there's been some unwanted manipulation done to the collection,
# we'll have to remove everything to fill it up again
if(nb.docs != 12 & nb.docs != 0){
horoscope$remove('{}')
nb.docs <- 0
} else if (nb.docs == 12){
#make sure we have the same sign names
sign.names <- horoscope$find(fields = '{"sign_name" : true, "_id": false}')
both <- sign_name %in% unlist(sign.names)
if (FALSE %in% both){
nb.docs <- 0
}
}
#if nb.docs = 0 : it means that the collection was never filled or was emptied,
#we'll create the 12 docs, one for each sign
#we'll start by giving the sign name field:
if(nb.docs == 0){
for(sn in sign_name) {
horoscope$insert(paste0('{ \"sign_name\" : \"', sn, '\" }'))
}
}
#We can add sign_name field as an index since we will use it for all the queries
indexes <- horoscope$index()
if(nrow(indexes) == 1){
#add sign_name as index:
horoscope$index('{ "sign_name" : 1 }')
}
#At this point, we're sure to have 12 docs with the right names
# Now we'll call the API to update the docs:
url <- "https://sameer-kumar-aztro-v1.p.rapidapi.com/"
queryString <- list(
sign = '',
day = 'tomorrow'
)
#iterate on every sign to update the 12 docs:
for (s in sign_name) {
#get the data of the sign name from the API
queryString$sign <- s
response <- VERB("POST", url,
add_headers('X-RapidAPI-Key' = 'adeb7a202dmsh5fea2b1e4e8b773p17937bjsna13b311ffa5e',
'X-RapidAPI-Host' = 'sameer-kumar-aztro-v1.p.rapidapi.com'),
query = queryString,
content_type("application/octet-stream"))
#the data we want is stored in this list
cont <- content(response)
col.names <- names(cont)
#iterate on every 'column' of the list and put it as a field of the doc with the s sign name:
for(field in col.names){
query <- paste0(' { \"sign_name\" : \"', s, '\"} ')
update <- paste0( '{\"$set\" : { \"',
field,
'\" : \"',
cont[[field]],
'\"}}' )
horoscope$update(query = query, update = update )
}
}
library(mongolite)
require(highcharter)
library(dplyr)
library(httr)
library(jsonlite)
Bikes <- mongo(collection = "Bikes", db = "AKZN")
Bikes$remove('{}')
res = GET(paste0("https://opendata.paris.fr/api/records/1.0/search/?dataset=velib-disponibilite-en-temps-reel&q=&rows=1000&facet=nom_arrondissement_communes"))
data = fromJSON(rawToChar(res$content))
dfp <- data.frame(data)
df <- dfp$records.fields
df <- df[,-c(1,2,5,6,8,10,11,13)]
grp_nom_arrondissement_communes <- df %>% group_by(nom_arrondissement_communes) %>%
summarise(ebike_available = sum(ebike),
mbike_available = sum(mechanical),
numbikes_available = sum(numbikesavailable),
capacity = sum(capacity),
city = "IDF",
.groups = 'drop'
)
Bikes$insert(grp_nom_arrondissement_communes)
res = GET(paste0("https://download.data.grandlyon.com/ws/rdata/jcd_jcdecaux.jcdvelov/all.json?maxfeatures=-1&start=1"))
data = fromJSON(rawToChar(res$content))
df <- data$values$total_stands
df$commune <- data$values$commune
grp_nom_arrondissement_communes <- df %>% group_by(commune) %>%
summarise(ebike_available = sum(availabilities$electricalBikes),
mbike_available = sum(availabilities$mechanicalBikes),
numbikes_available = sum(availabilities$bikes),
capacity = sum(capacity),
city="Lyon",
.groups = 'drop'
)
Bikes$insert(grp_nom_arrondissement_communes)
res = GET("https://opendata.lillemetropole.fr/api/records/1.0/search/?dataset=vlille-realtime&q=&rows=500&facet=libelle&facet=nom&facet=commune&facet=etat&facet=type&facet=etatconnexion")
data = fromJSON(rawToChar(res$content))
df <- data$records$fields
df <- df[,-c(3,4,5,6,8,9,10,11,12)]
grp_nom_arrondissement_communes <- df %>% group_by(commune) %>%
summarise(
numbikes_available = sum(nbvelosdispo),
capacity = sum(nbvelosdispo)+sum(nbplacesdispo),
city="Lille",
.groups = 'drop'
)
Bikes$insert(grp_nom_arrondissement_communes)
res = GET("https://data.toulouse-metropole.fr/api/records/1.0/search/?dataset=api-velo-toulouse-temps-reel&q=&rows=50")
data = fromJSON(rawToChar(res$content))
df <- data$records$fields
grp_nom_arrondissement_communes <- df %>% group_by(address) %>%
summarise(numbikes_available = sum(available_bikes),
capacity = sum(bike_stands),
city="Toulouse",
.groups = 'drop'
)
Bikes$insert(grp_nom_arrondissement_communes)
library(shiny); runApp('D:/studies/masterAMSD/M1/S1/linux/projetLinux/Projet_linux/Kenzi/bike_dashboard.R')
